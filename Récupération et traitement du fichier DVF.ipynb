{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8da7bd",
   "metadata": {},
   "source": [
    "# Récupération et traitement du fichier DVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3111cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des années à télécharger\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dvf(years, base_url='https://files.data.gouv.fr/geo-dvf/latest/csv/', output_file='full_dvf.csv'):\n",
    "    df_list = []\n",
    "\n",
    "    for year in years:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Étape 1: Télécharger le fichier\n",
    "        url = f'{base_url}{year}/full.csv.gz'\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            decompressed_file = gzip.decompress(response.content)\n",
    "            df = pd.read_csv(io.StringIO(decompressed_file.decode('utf-8')))\n",
    "            print(f\"Étape 1 ({year}): Téléchargement du fichier terminé - Temps écoulé: {time.time() - start_time:.2f} secondes\")\n",
    "\n",
    "            # Étape 2: Filtrer les lignes avec la valeur 'Vente' dans la colonne 'nature_mutation'\n",
    "            start_time = time.time()\n",
    "            df = df[df['nature_mutation'] == 'Vente']\n",
    "            print(f\"Étape 2 ({year}): Filtrage 'Vente' terminé - Temps écoulé: {time.time() - start_time:.2f} secondes\")\n",
    "\n",
    "            # Étape 3: Supprimer les lignes avec une valeur null dans la colonne 'surface_reelle_bati'\n",
    "            start_time = time.time()\n",
    "            df = df.dropna(subset=['surface_reelle_bati'])\n",
    "            print(f\"Étape 3 ({year}): Suppression des valeurs null dans 'surface_reelle_bati' terminée - Temps écoulé: {time.time() - start_time:.2f} secondes\")\n",
    "\n",
    "            # Étape 4: Supprimer les lignes avec une valeur null dans la colonne 'valeur_fonciere'\n",
    "            start_time = time.time()\n",
    "            df = df.dropna(subset=['valeur_fonciere'])\n",
    "            print(f\"Étape 4 ({year}): Suppression des valeurs null dans 'valeur_fonciere' terminée - Temps écoulé: {time.time() - start_time:.2f} secondes\")\n",
    "\n",
    "            # Étape 5: Filtrer les lignes avec les valeurs 'Maison' ou 'Appartement' dans la colonne 'type_local'\n",
    "            start_time = time.time()\n",
    "            df = df[df['type_local'].isin(['Maison', 'Appartement'])]\n",
    "            print(f\"Étape 5 ({year}): Filtrage 'Maison' et 'Appartement' terminé - Temps écoulé: {time.time() - start_time:.2f} secondes\")\n",
    "\n",
    "            # Étape 6: Supprimer les lignes avec une valeur null dans les colonnes 'longitude' et 'latitude'\n",
    "            start_time = time.time()\n",
    "            df = df.dropna(subset=['longitude', 'latitude'])\n",
    "            print(f\"Étape 6 ({year}): Suppression des valeurs nulles dans 'longitude' et 'latitude' effectuée - Temps écoulé: {time.time() - start_time:.2f} secondes\")\n",
    "            \n",
    "            # Ajouter le DataFrame à la liste\n",
    "            df_list.append(df)\n",
    "        else:\n",
    "            print(f\"Erreur lors du téléchargement du fichier pour l'année {year}\")\n",
    "\n",
    "    # Concaténer les DataFrames\n",
    "    concatenated_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Enregistrer le DataFrame concaténé dans un fichier CSV\n",
    "    concatenated_df.to_csv(output_file, index=False)\n",
    "    print(f'Fichier CSV concaténé enregistré : {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae557292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appeler la fonction avec les années souhaitées\n",
    "process_dvf(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfa685",
   "metadata": {},
   "source": [
    "# Analyse du fichier final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b573d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dvf= pd.read_csv('full_dvf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(full_dvf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96c23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e518a71341917c645f60d9cc5f8f3f6f2667c2d31c361cf9c4364ceaee59fa29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
